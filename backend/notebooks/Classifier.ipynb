{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "KNN score: 0.961111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\moje pliki\\programy\\.python_envs\\temperaturereader\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "e:\\moje pliki\\programy\\.python_envs\\temperaturereader\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression score: 0.938889\n",
      "auto\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, neighbors, linear_model\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X_digits = digits.data\n",
    "y_digits = digits.target\n",
    "\n",
    "n_samples = len(X_digits)\n",
    "print(n_samples)\n",
    "\n",
    "X_train = X_digits[:int(.9 * n_samples)]\n",
    "y_train = y_digits[:int(.9 * n_samples)]\n",
    "X_test = X_digits[int(.9 * n_samples):]\n",
    "y_test = y_digits[int(.9 * n_samples):]\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "logistic = linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "print('KNN score: %f' % knn.fit(X_train, y_train).score(X_test, y_test))\n",
    "print('LogisticRegression score: %f'\n",
    "      % logistic.fit(X_train, y_train).score(X_test, y_test))\n",
    "\n",
    "print(knn.algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        88\n",
      "           1       0.99      0.97      0.98        91\n",
      "           2       0.99      0.99      0.99        86\n",
      "           3       0.98      0.87      0.92        91\n",
      "           4       0.99      0.96      0.97        92\n",
      "           5       0.95      0.97      0.96        91\n",
      "           6       0.99      0.99      0.99        91\n",
      "           7       0.96      0.99      0.97        89\n",
      "           8       0.94      1.00      0.97        88\n",
      "           9       0.93      0.98      0.95        92\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       899\n",
      "   macro avg       0.97      0.97      0.97       899\n",
      "weighted avg       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
